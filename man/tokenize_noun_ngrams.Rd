% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenizer.R
\name{tokenize_noun_ngrams}
\alias{tokenize_noun_ngrams}
\title{N-gram Tokenizer}
\usage{
tokenize_noun_ngrams(
  x,
  n = 3L,
  n_min = n,
  stopwords = character(),
  ngram_delim = " ",
  simplify = FALSE,
  type = c("noun", "noun2"),
  user_dic = NULL
)
}
\arguments{
\item{x}{character. 토큰화할 문자열 벡터}

\item{n}{integer. n-gram의 단어 수입니다. 1 이상의 정수.}

\item{n_min}{integer. 이것은 1보다 크거나 같고 n보다 작거나 같은 정수여야 함}

\item{stopwords}{character. n-그램에서 제외할 불용어의 문자형 벡터}

\item{ngram_delim}{character. 생성된 n-gram에서 단어 사이의 구분 기호}

\item{simplify}{logical. 기본값은 FALSE로 입력 길이에 관계없이 일관된 값이 
반환되도록 list 객체로 반환. TRUE인 경우 x가 단일 값일경우에는 문자 벡터를 반환}
}
\value{
토큰화된 character 벡터를 성분으로 갖는 list. simplify값이 TRUE이고 
x가 단일값일 때에는 character 벡터
}
\description{
명사를 추출하여 n-gram으로 토큰화합니다.
}
\examples{
\donttest{
tokenize_noun_ngrams(president_speech$doc[1:2])

# simplify = TRUE
tokenize_noun_ngrams(president_speech$doc[1], simplify = TRUE)

str <- "신혼부부나 주말부부는 놀이공원 자유이용권을 즐겨 구매합니다."

tokenize_noun_ngrams(str)

# 불용어 처리
tokenize_noun_ngrams(str, stopwords = "구매")
 
# 사용자 정의 사전 사용
dic_path <- system.file("dic", package = "bitTA")
dic_file <- glue::glue("{dic_path}/buzz_dic.dic")
tokenize_noun_ngrams(str, simplify = TRUE, user_dic = dic_file)

# n_min
tokenize_noun_ngrams(str, n_min = 1, user_dic = dic_file)

# ngram_delim
tokenize_noun_ngrams(str, ngram_delim = ":", user_dic = dic_file)
}

}

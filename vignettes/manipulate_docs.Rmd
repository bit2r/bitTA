---
title: "Manipulate Documents"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Manipulate Documents}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r environment, echo = FALSE, message = FALSE, warning=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "", out.width = "600px", dpi = 70,
                      echo = TRUE, message = FALSE, warning = FALSE)
options(tibble.print_min = 4L, tibble.print_max = 4L)
```

## Manipulate Documents

`Manipulate Documents`라 쓰고 텍스트 `**텍스트 데이터 정제**`라 이야기 합니다. 

### 텍스트 데이터 정제
신문 기사나 소설, 수필과 같은 잘 정리된 텍스트 문서와 뉴스 진행자들이 전하는 뉴스 멘트들은 맞춤법에 부합하는 품질 높은 텍스트 데이터들입니다.

실제로 텍스트 분석에 직면하면 환상은 저 먼 나라의 이야기가 되어 버립니다. 맞춤법, 띄어쓰기가 무시된 텍스트는 그나마 애교가 있는 수준입니다.

통화 내용을 STT(Speech to Text)기법으로 텍스트로 변환한 데이터는 변환기의 성능이 완벽하지 않아서 품질이 매우 낮습니다. 화자와 청자의 의도는 유추하여 이해할 수 있겠으나, 텍스트 분석이라는 기계를 시켜서 수행하는 데이터 분석에는 부족함이 많습니다. 

카페나 블로그의 게시글, SNS 채널의 글은 **맞춤법, 띄어쓰기에 취약하고, 신조어나 암호같은 줄임말, 완전하지 않은 문장들이 포함**됩니다. 경우에 따라서는 수집 과정에서 기술적인 한계로, **불필요한 텍스트들이 포함**되기도 합니다. 그래서 데이터 정제없이 분석할 수 없는 경우가 많습니다. 
어떤 경우는 수집한 텍스트 데이터가 데이터 **분석을 수행하려는 목적과 부합하지 않아서 제거해야할** 경우도 있습니다. 

이처럼 텍스트 데이터 분석은 일반적인 데이터 분석에 비해서 데이터 정제가 차지하는 비중은 매우 큽니다. 텍스트 데이터 정제 성능은 텍스트 데이터 분석 성능과 직결되기 때문입니다.

### 형태소분석과 데이터의 품질

텍스트 데이터 분석은 보통 형태소분석을 통해서 품사를 태깅하고, 품사 기반으로 토큰화된 단어로 텍스트 분석을 수행합니다.

문제는 분석에 사용하는 형태소분석기가, 문법과 띄어쓰기에 부합되는 품질 좋은 양질의 텍스트 데이터를 학습해서 만들어진 모델을 이용한다는 점입니다. 그래서 형태소분석을 수행하는 데이터의 품질이 떨어진다면, 형태소분석의 결과도 만족스럽지 못합니다. 어찌 보면 이러한 점이 데이터 정제를 하는 가장 큰 이유 중에 하나입니다.

문서의 품질이 높은 경우에도 문제가 발생할 수 있습니다. 형태소분석기에 사용한 학습 데이터는 우리가 일상 생활에서 이야기하는 대화의 주제, 혹은 직업, 학문과 예술, 종교 등 여러 분야의 내용을 모두 담지 못합니다. **학습 데이터는 지극히 일부의 샘플링된 문장들**이라는 점입니다. 그래서 통상적인 생활에서 발화되는 단어가 아닌 전문성이 필요한 영역의 단어를 이해하지 못합니다.

`알파고`가 쏘아 올린 화두가 학계와 필드의 AI 혁신을 이끌었습니다. 아마도 5년전에는 대중들은 `알파고`라는 단어에 익숙하지 못했을 겁니다. 

이처럼 형태소분석기가 취약한 **신조어나, 특정 영역에서 사용하는 전문용어들은 사용자 정의 사전에 등록**해서 형태소분석기가 이를 이해할 수 있도록 도와줘야 합니다. 이러한 작업들도 광의적으로 데이터를 정제를 수행하는 덱트스 데이터의 조작(Manipulate Documents)입니다.

## bitTA의 텍스트 데이터 정제 기능

### 


